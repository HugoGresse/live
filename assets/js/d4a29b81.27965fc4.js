(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[760],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return c},kt:function(){return m}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(n),m=a,h=p["".concat(s,".").concat(m)]||p[m]||d[m]||o;return n?r.createElement(h,i(i({ref:t},c),{},{components:n})):r.createElement(h,i({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=p;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var u=2;u<o;u++)i[u]=n[u];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},6007:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return l},metadata:function(){return s},toc:function(){return u},default:function(){return d}});var r=n(2122),a=n(9756),o=(n(7294),n(3905)),i=["components"],l={id:"connecting-to-a-server",sidebar_position:6},s={unversionedId:"tutorials/connecting-to-a-server",id:"tutorials/connecting-to-a-server",isDocsHomePage:!1,title:"Connecting to a Server Model",description:"In this tutorial, we will connect our PyTorch Live demo to the server we created in the GPT server model tutorial.",source:"@site/docs/tutorials/connecting-to-a-server.mdx",sourceDirName:"tutorials",slug:"/tutorials/connecting-to-a-server",permalink:"/docs/tutorials/connecting-to-a-server",editUrl:"https://github.com/pytorch/live/edit/main/website/docs/tutorials/connecting-to-a-server.mdx",version:"current",sidebarPosition:6,frontMatter:{id:"connecting-to-a-server",sidebar_position:6},sidebar:"docs",previous:{title:"Server Model",permalink:"/docs/tutorials/server-model"},next:{title:"FAQ",permalink:"/docs/tutorials/faq"}},u=[{value:"In this tutorial, we will connect our PyTorch Live demo to the server we created in the GPT server model tutorial.",id:"in-this-tutorial-we-will-connect-our-pytorch-live-demo-to-the-server-we-created-in-the-gpt-server-model-tutorial",children:[]},{value:"Create a new React Native project",id:"create-a-new-react-native-project",children:[]},{value:"Adding UI",id:"adding-ui",children:[]},{value:"Handling user input",id:"handling-user-input",children:[]},{value:"Making a request to the server",id:"making-a-request-to-the-server",children:[]},{value:"Triggering server request from UI",id:"triggering-server-request-from-ui",children:[]},{value:"Next steps",id:"next-steps",children:[]}],c={toc:u};function d(e){var t=e.components,l=(0,a.Z)(e,i);return(0,o.kt)("wrapper",(0,r.Z)({},c,l,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("div",{className:"tutorial-page"},(0,o.kt)("h3",{id:"in-this-tutorial-we-will-connect-our-pytorch-live-demo-to-the-server-we-created-in-the-gpt-server-model-tutorial"},"In this tutorial, we will connect our PyTorch Live demo to the server we created in ",(0,o.kt)("a",{parentName:"h3",href:"/docs/tutorials/server-model"},"the GPT server model tutorial"),"."),(0,o.kt)("p",null,"You will need to have completed that tutorial for this one to work as is. If you haven't installed the PyTorch Live CLI yet, please ",(0,o.kt)("a",{parentName:"p",href:"get-started"},"follow this tutorial")," to get started."),(0,o.kt)("p",null,"If you are just looking for an example of how to connect to your own server model, feel free to follow along and adapt what we do to your situation."),(0,o.kt)("h2",{id:"create-a-new-react-native-project"},"Create a new React Native project"),(0,o.kt)("p",null,"We will start by creating a new React Native project with the PyTorch Live template using the CLI. Run the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli init GPTClient\n")),(0,o.kt)("p",null,"Once that is done, let's go into a our newly created project and run it!"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"cd GPTClient\nyarn android\n")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(173).Z,title:"Screenshot of app after fresh init with CLI"})),(0,o.kt)("h2",{id:"adding-ui"},"Adding UI"),(0,o.kt)("p",null,"The aim of this tutorial is to help you integrate your PyTorch Live apps with server models, so we will not spend much time on the UI. We will add some handling for interactions, but won't discuss layout or styling."),(0,o.kt)("p",null,"That being said, we will start by copying the following code into the file ",(0,o.kt)("inlineCode",{parentName:"p"},"src/demos/MyDemos.tsx"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},"import React from 'react';\nimport {\n  Text,\n  TextInput,\n  TouchableOpacity,\n  StyleSheet,\n  View,\n  ScrollView,\n  SafeAreaView,\n} from 'react-native';\n\nexport default function MyDemo() {\n  return (\n    <SafeAreaView style={styles.container}>\n      <ScrollView\n        style={styles.scrollContainer}\n        keyboardShouldPersistTaps=\"handled\">\n        <View style={styles.row}>\n          <Text style={styles.label}>\n            This example shows how to send and receive text data via POST\n            request. You can repurpose this to build an NLP prototype (eg,\n            GPT-3) if you implement a server-side AI model.\n          </Text>\n          <View style={styles.promptBox}>\n            <TextInput\n              style={styles.textArea}\n              placeholder=\"Once upon a time...\"\n              placeholderTextColor=\"#00000033\"\n              multiline={true}\n              numberOfLines={6}\n              autoCorrect={false}\n            />\n            <TouchableOpacity>\n              <View style={styles.sendButton}>\n                <Text style={styles.buttonText}>Send</Text>\n              </View>\n            </TouchableOpacity>\n          </View>\n        </View>\n\n        <View style={[styles.row]}>\n          <Text style={styles.label}>Response:</Text>\n          <Text style={styles.answer}></Text>\n        </View>\n      </ScrollView>\n    </SafeAreaView>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n  },\n  scrollContainer: {\n    backgroundColor: '#ffcac2',\n    padding: 30,\n  },\n  row: {\n    flex: 1,\n    padding: 15,\n    flexDirection: 'column',\n    alignItems: 'flex-start',\n  },\n  rowHidden: {\n    opacity: 0,\n  },\n  label: {\n    fontSize: 14,\n    color: '#00000099',\n    marginBottom: 5,\n  },\n  textArea: {\n    flex: 1,\n    alignSelf: 'stretch',\n    textAlignVertical: 'top',\n    marginLeft: 5,\n    color: '#112233',\n    fontSize: 16,\n  },\n  promptBox: {\n    flex: 1,\n    flexDirection: 'column',\n    borderColor: '#ff4c2c33',\n    backgroundColor: '#ffffff',\n    fontSize: 16,\n    borderRadius: 5,\n    borderWidth: 1,\n    padding: 10,\n    marginRight: 5,\n    marginVertical: 20,\n    alignItems: 'flex-end',\n    alignSelf: 'stretch',\n  },\n  sendButton: {\n    backgroundColor: '#812ce5',\n    paddingVertical: 15,\n    paddingHorizontal: 40,\n    alignSelf: 'auto',\n    borderRadius: 5,\n  },\n  buttonText: {\n    color: '#ffffff',\n    fontSize: 14,\n    fontWeight: 'bold',\n    marginBottom: 2,\n  },\n  answer: {\n    fontSize: 21,\n    color: '#000000',\n  },\n  smallLabel: {\n    fontSize: 12,\n    color: '#667788',\n    fontFamily: 'Courier New',\n  },\n});\n")),(0,o.kt)("p",null,"Now you should be see the UI that looks exactly like the screenshot below. However, note that nothing happens when you touch the button. We'll fix that in the next section."),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(6403).Z,title:"Screenshot of UI created with initial code"})),(0,o.kt)("h2",{id:"handling-user-input"},"Handling user input"),(0,o.kt)("p",null,"Before we make a request to our server, let's make sure we can handle button clicks and capture the user input."),(0,o.kt)("p",null,"Our changes are simple. They include:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Add ",(0,o.kt)("inlineCode",{parentName:"li"},"useState")," to our import statement from ",(0,o.kt)("inlineCode",{parentName:"li"},"react")),(0,o.kt)("li",{parentName:"ul"},"Add ",(0,o.kt)("inlineCode",{parentName:"li"},"Keyboard")," to our import statement from ",(0,o.kt)("inlineCode",{parentName:"li"},"react-native")),(0,o.kt)("li",{parentName:"ul"},"Track state of the ",(0,o.kt)("inlineCode",{parentName:"li"},"result")," of our model and the ",(0,o.kt)("inlineCode",{parentName:"li"},"prompt")," the user inputs"),(0,o.kt)("li",{parentName:"ul"},"Create a placeholder function, ",(0,o.kt)("inlineCode",{parentName:"li"},"generateText()"),", that simply dismisses the keyboard and makes the ",(0,o.kt)("inlineCode",{parentName:"li"},"result")," equal to the prompt the user inputs"),(0,o.kt)("li",{parentName:"ul"},"Update the ",(0,o.kt)("inlineCode",{parentName:"li"},"prompt")," state value when the text changes in the input box"),(0,o.kt)("li",{parentName:"ul"},"Trigger our placeholder function, ",(0,o.kt)("inlineCode",{parentName:"li"},"generateText()"),', when the user presses the "Send" button'),(0,o.kt)("li",{parentName:"ul"},"Display the ",(0,o.kt)("inlineCode",{parentName:"li"},"result")," state value below the input")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx" {1,10,14-19,39-42,51}',title:'"MyDemos.tsx"',"{1,10,14-19,39-42,51}":!0},"import React, {useState} from 'react';\nimport {\n  Text,\n  TextInput,\n  TouchableOpacity,\n  StyleSheet,\n  View,\n  ScrollView,\n  SafeAreaView,\n  Keyboard,\n} from 'react-native';\n\nexport default function MyDemo() {\n  const [result, setResult] = useState('');\n  const [prompt, setPrompt] = useState('');\n  function generateText() {\n    Keyboard.dismiss();\n    setResult(prompt);\n  }\n  return (\n    <SafeAreaView style={styles.container}>\n      <ScrollView\n        style={styles.scrollContainer}\n        keyboardShouldPersistTaps=\"handled\">\n        <View style={styles.row}>\n          <Text style={styles.label}>\n            This example shows how to send and receive text data via POST\n            request. You can repurpose this to build an NLP prototype (eg,\n            GPT-3) if you implement a server-side AI model.\n          </Text>\n          <View style={styles.promptBox}>\n            <TextInput\n              style={styles.textArea}\n              placeholder=\"Once upon a time...\"\n              placeholderTextColor=\"#00000033\"\n              multiline={true}\n              numberOfLines={6}\n              autoCorrect={false}\n              onChangeText={setPrompt}\n              value={prompt}\n            />\n            <TouchableOpacity onPress={generateText}>\n              <View style={styles.sendButton}>\n                <Text style={styles.buttonText}>Send</Text>\n              </View>\n            </TouchableOpacity>\n          </View>\n        </View>\n        <View style={[styles.row]}>\n          <Text style={styles.label}>Response:</Text>\n          <Text style={styles.answer}>{result}</Text>\n        </View>\n      </ScrollView>\n    </SafeAreaView>\n  );\n}\n .\n .\n .\n")),(0,o.kt)("p",null,"Once you add these changes and the app refreshes you should see the following behavior:"),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(9596).Z})),(0,o.kt)("h2",{id:"making-a-request-to-the-server"},"Making a request to the server"),(0,o.kt)("p",null,"With our interaction handling ready to go, we can write the code that will make a request to our server."),(0,o.kt)("p",null,"We will add one function called ",(0,o.kt)("inlineCode",{parentName:"p"},"fetchData"),". It does the following:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Checks to make sure we have set our IP address"),(0,o.kt)("li",{parentName:"ul"},"Creates the URL of our server using our IP address"),(0,o.kt)("li",{parentName:"ul"},"Creates a FormData object that is used to send input to the server"),(0,o.kt)("li",{parentName:"ul"},"Adds the user input prompt to the form data with the key ",(0,o.kt)("inlineCode",{parentName:"li"},'"prompt"')," (what our server is expecting)"),(0,o.kt)("li",{parentName:"ul"},"Kicks off a request using the ",(0,o.kt)("a",{parentName:"li",href:"https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch"},(0,o.kt)("inlineCode",{parentName:"a"},"fetch")," API")," and waits for the Response"),(0,o.kt)("li",{parentName:"ul"},'Checks if the request succeeded and then returns either the generated text from the server or the string "Error" if it failed')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx" {6-34}',title:'"MyDemos.tsx"',"{6-34}":!0},"import React, {useState} from 'react';\n.\n.\n.\n\nasync function fetchData(prompt: string): Promise<string> {\n  // IMPORTANT: You MUST set `ipAddress` to your computer's IP address\n  // You also must make sure that your computer and your device are on the same network\n  const ipAddress = null;\n  if (ipAddress === null) {\n    throw Error('You must fill in your own IP address!');\n  }\n  const url = `http://${ipAddress}:5000/gpt`;\n\n  // compose the formdata object to be sent via POST\n  const formdata = new FormData();\n  formdata.append('prompt', prompt);\n\n  // fetch with a POST request\n  const data = await fetch(url, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'multipart/form-data',\n    },\n    body: formdata,\n  });\n\n  if (data.ok) {\n    const jsonResponse = await data.json();\n    return jsonResponse.generated_text;\n  } else {\n    return 'Error';\n  }\n}\n\n export default function MyDemo() {\n.\n.\n.\n")),(0,o.kt)("h2",{id:"triggering-server-request-from-ui"},"Triggering server request from UI"),(0,o.kt)("p",null,"The last step is to integrate the ",(0,o.kt)("inlineCode",{parentName:"p"},"fetchData")," function we just created into the UI that we have built."),(0,o.kt)("p",null,"In addition to calling the function, we will also make sure to handle the loading state, as the model is a bit slow."),(0,o.kt)("p",null,"Here's a list of the changes:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Import ",(0,o.kt)("inlineCode",{parentName:"li"},"ActivityIndicator")," from ",(0,o.kt)("inlineCode",{parentName:"li"},"react-native")," so we can display a spinner while the server is doing it's work"),(0,o.kt)("li",{parentName:"ul"},"Create a new state variable to track ",(0,o.kt)("inlineCode",{parentName:"li"},"loading")," (when we are waiting on our server)"),(0,o.kt)("li",{parentName:"ul"},"Re-write our ",(0,o.kt)("inlineCode",{parentName:"li"},"generateText")," function:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Make it an ",(0,o.kt)("inlineCode",{parentName:"li"},"async")," function so the server call happens in the background and doesn't freeze the device"),(0,o.kt)("li",{parentName:"ul"},"Before fetching, set ",(0,o.kt)("inlineCode",{parentName:"li"},"loading")," to true and clear out any previous ",(0,o.kt)("inlineCode",{parentName:"li"},"result")),(0,o.kt)("li",{parentName:"ul"},"Kick off and wait for the response from our server with our ",(0,o.kt)("inlineCode",{parentName:"li"},"fetchData")," function"),(0,o.kt)("li",{parentName:"ul"},"When we get the data back, set our ",(0,o.kt)("inlineCode",{parentName:"li"},"result")," to the returned text and set loading to ",(0,o.kt)("inlineCode",{parentName:"li"},"false")))),(0,o.kt)("li",{parentName:"ul"},"Disable our button while ",(0,o.kt)("inlineCode",{parentName:"li"},"loading")," so the user doesn't send requests twice"),(0,o.kt)("li",{parentName:"ul"},"Display an ",(0,o.kt)("inlineCode",{parentName:"li"},"<ActivityIndicator />")," in the results box while the server is loading")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx" {11,21,23-32,56,67}',title:'"MyDemos.tsx"',"{11,21,23-32,56,67}":!0},"import React, {useState} from 'react';\nimport {\n  Text,\n  TextInput,\n  TouchableOpacity,\n  StyleSheet,\n  View,\n  ScrollView,\n  SafeAreaView,\n  Keyboard,\n  ActivityIndicator,\n} from 'react-native';\n\n.\n.\n.\n\nexport default function MyDemo() {\n  const [result, setResult] = useState('');\n  const [prompt, setPrompt] = useState('');\n  const [loading, setLoading] = useState(false);\n\n  const generateText = async () => {\n    Keyboard.dismiss();\n    setLoading(true);\n    setResult('');\n\n    const data: string = await fetchData(prompt);\n\n    setResult(data);\n    setLoading(false);\n  };\n\n  return (\n    <SafeAreaView style={styles.container}>\n      <ScrollView\n        style={styles.scrollContainer}\n        keyboardShouldPersistTaps=\"handled\">\n        <View style={styles.row}>\n          <Text style={styles.label}>\n            This example shows how to send and receive text data via POST\n            request. You can repurpose this to build an NLP prototype (eg,\n            GPT-3) if you implement a server-side AI model.\n          </Text>\n          <View style={styles.promptBox}>\n            <TextInput\n              style={styles.textArea}\n              onChangeText={txt => setPrompt(txt)}\n              placeholder=\"Once upon a time...\"\n              placeholderTextColor=\"#00000033\"\n              multiline={true}\n              numberOfLines={6}\n              autoCorrect={false}\n              value={prompt}\n            />\n            <TouchableOpacity disabled={loading} onPress={generateText}>\n              <View style={styles.sendButton}>\n                <Text style={styles.buttonText}>Send</Text>\n              </View>\n            </TouchableOpacity>\n          </View>\n        </View>\n\n        <View style={[styles.row]}>\n          <Text style={styles.label}>Response:</Text>\n          <Text style={styles.answer}>\n            {loading && <ActivityIndicator size=\"small\" color=\"tomato\" />}\n            {result}\n          </Text>\n        </View>\n      </ScrollView>\n    </SafeAreaView>\n  );\n}\n.\n.\n.\n")),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"If you are trying to run this from a physical Android device, you will also have to edit the file ",(0,o.kt)("inlineCode",{parentName:"p"},"network_security_config.xml")," in the ",(0,o.kt)("inlineCode",{parentName:"p"},"GPTClient/android/app/src/main/res/xml/")," directory to add support for your IP address. Emulators should already work.\nSee below what that change should look like."))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-xml",metastring:'title="network_security_config.xml (only needed for testing with physical Android devices)" {6}',title:'"network_security_config.xml',"(only":!0,needed:!0,for:!0,testing:!0,with:!0,physical:!0,Android:!0,'devices)"':!0,"{6}":!0},'<?xml version="1.0" encoding="utf-8"?>\n<network-security-config>\n    <domain-config cleartextTrafficPermitted="true">\n        <domain includeSubdomains="true">10.0.2.2</domain>\n        <domain includeSubdomains="true">localhost</domain>\n        <domain includeSubdomains="true">your.ip.address</domain>\n    </domain-config>\n</network-security-config>\n')),(0,o.kt)("p",null,"With those changes completed, make sure your server is running and ready to go and you should be able to see results of the GPT model on your app!"),(0,o.kt)("p",null,"Note that the GIF below is drastically sped up. Inference with the GPT model takes some time."),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(8421).Z})),(0,o.kt)("p",null,"You can find the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/pytorch/live/tree/main/examples/gpt3-server-tutorials/GPTClient"},"completed versions of the source code")," we've written in this tutorial in the ",(0,o.kt)("inlineCode",{parentName:"p"},"examples")," folder Pytorch Live GitHub repo."),(0,o.kt)("h2",{id:"next-steps"},"Next steps"),(0,o.kt)("p",null,"Want to enhance your server to support a model with more complex input like images? Check out our tutorial with VQGAN + CLIP to generate images from text descriptions.")))}d.isMDXComponent=!0},173:function(e,t,n){"use strict";t.Z=n.p+"assets/images/cli-fresh-install-25e23131120ec484ac24093ae32f4e52.png"},9596:function(e,t,n){"use strict";t.Z=n.p+"assets/images/echo-working-2404e219aa476991e586b32d3449bb62.gif"},6403:function(e,t,n){"use strict";t.Z=n.p+"assets/images/initial-ui-c1e3fe664aefb8ef84df5e7a07003e3a.png"},8421:function(e,t,n){"use strict";t.Z=n.p+"assets/images/working-gpt-demo-39e8d23b22385c57f3f6b2ba62a57ab6.gif"}}]);