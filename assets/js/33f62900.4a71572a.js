(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[469],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return p},kt:function(){return m}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),c=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=c(n),m=a,v=u["".concat(s,".").concat(m)]||u[m]||d[m]||o;return n?r.createElement(v,i(i({ref:t},p),{},{components:n})):r.createElement(v,i({ref:t},p))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},8215:function(e,t,n){"use strict";var r=n(7294);t.Z=function(e){var t=e.children,n=e.hidden,a=e.className;return r.createElement("div",{role:"tabpanel",hidden:n,className:a},t)}},1395:function(e,t,n){"use strict";n.d(t,{Z:function(){return p}});var r=n(7294),a=n(944),o=n(6010),i="tabItem_1uMI",l="tabItemActive_2DSg";var s=37,c=39;var p=function(e){var t=e.lazy,n=e.block,p=e.defaultValue,d=e.values,u=e.groupId,m=e.className,v=(0,a.Z)(),h=v.tabGroupChoices,f=v.setTabGroupChoices,y=(0,r.useState)(p),b=y[0],k=y[1],g=r.Children.toArray(e.children),w=[];if(null!=u){var _=h[u];null!=_&&_!==b&&d.some((function(e){return e.value===_}))&&k(_)}var N=function(e){var t=e.currentTarget,n=w.indexOf(t),r=d[n].value;k(r),null!=u&&(f(u,r),setTimeout((function(){var e,n,r,a,o,i,s,c;(e=t.getBoundingClientRect(),n=e.top,r=e.left,a=e.bottom,o=e.right,i=window,s=i.innerHeight,c=i.innerWidth,n>=0&&o<=c&&a<=s&&r>=0)||(t.scrollIntoView({block:"center",behavior:"smooth"}),t.classList.add(l),setTimeout((function(){return t.classList.remove(l)}),2e3))}),150))},C=function(e){var t,n;switch(e.keyCode){case c:var r=w.indexOf(e.target)+1;n=w[r]||w[0];break;case s:var a=w.indexOf(e.target)-1;n=w[a]||w[w.length-1]}null==(t=n)||t.focus()};return r.createElement("div",{className:"tabs-container"},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":n},m)},d.map((function(e){var t=e.value,n=e.label;return r.createElement("li",{role:"tab",tabIndex:b===t?0:-1,"aria-selected":b===t,className:(0,o.Z)("tabs__item",i,{"tabs__item--active":b===t}),key:t,ref:function(e){return w.push(e)},onKeyDown:C,onFocus:N,onClick:N},n)}))),t?(0,r.cloneElement)(g.filter((function(e){return e.props.value===b}))[0],{className:"margin-vert--md"}):r.createElement("div",{className:"margin-vert--md"},g.map((function(e,t){return(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==b})}))))}},9443:function(e,t,n){"use strict";var r=(0,n(7294).createContext)(void 0);t.Z=r},944:function(e,t,n){"use strict";var r=n(7294),a=n(9443);t.Z=function(){var e=(0,r.useContext)(a.Z);if(null==e)throw new Error("`useUserPreferencesContext` is used outside of `Layout` Component.");return e}},9435:function(e,t,n){"use strict";n.d(t,{Z:function(){return o}});var r=n(7294),a="surveyLinkBox_YpLv";function o(e){var t="https://docs.google.com/forms/d/e/1FAIpQLScsB21xJWM_VANad5GcVkQqKB_BptS77axbunzs7ZkwoE5JUw/viewform?usp=pp_url&entry.1880917601="+e.docTitle.replace(/\s/g,"+");return r.createElement("a",{href:t,target:"_blank"},r.createElement("div",{className:a},"Share what we can improve!"))}},620:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return p},metadata:function(){return d},toc:function(){return u},default:function(){return v}});var r=n(2122),a=n(9756),o=(n(7294),n(3905)),i=n(1395),l=n(8215),s=n(9435),c=["components"],p={id:"prepare-custom-model",sidebar_position:4},d={unversionedId:"tutorials/prepare-custom-model",id:"tutorials/prepare-custom-model",isDocsHomePage:!1,title:"Prepare Custom Model",description:"In this tutorial, we will learn how to prepare a custom AI model so that it can be integrated into a PyTorch Live demo.",source:"@site/docs/tutorials/prepare-custom-model.mdx",sourceDirName:"tutorials",slug:"/tutorials/prepare-custom-model",permalink:"/docs/tutorials/prepare-custom-model",editUrl:"https://github.com/pytorch/live/edit/main/website/docs/tutorials/prepare-custom-model.mdx",version:"current",sidebarPosition:4,frontMatter:{id:"prepare-custom-model",sidebar_position:4},sidebar:"docs",previous:{title:"MNIST Digit Classification",permalink:"/docs/tutorials/mnist-digit-classification"},next:{title:"Server Model",permalink:"/docs/tutorials/server-model"}},u=[{value:"In this tutorial, we will learn how to prepare a custom AI model so that it can be integrated into a PyTorch Live demo.",id:"in-this-tutorial-we-will-learn-how-to-prepare-a-custom-ai-model-so-that-it-can-be-integrated-into-a-pytorch-live-demo",children:[]},{value:"Create Live Spec",id:"create-live-spec",children:[]},{value:"Bundle Live Spec with Model",id:"bundle-live-spec-with-model",children:[{value:"Set up Python virtual environment",id:"set-up-python-virtual-environment",children:[]},{value:"Install <code>torch</code> and <code>torchvision</code> dependencies.",id:"install-torch-and-torchvision-dependencies",children:[]}]},{value:"Give us feedback",id:"give-us-feedback",children:[]}],m={toc:u};function v(e){var t=e.components,n=(0,a.Z)(e,c);return(0,o.kt)("wrapper",(0,r.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("div",{className:"tutorial-page"},(0,o.kt)("h3",{id:"in-this-tutorial-we-will-learn-how-to-prepare-a-custom-ai-model-so-that-it-can-be-integrated-into-a-pytorch-live-demo"},"In this tutorial, we will learn how to prepare a custom AI model so that it can be integrated into a PyTorch Live demo."),(0,o.kt)("p",null,"PyTorch Live works with high-level data types such as images and strings. To run inference, these high-level data types need to be transformed into tensors and the model output needs to be transformed into high-level data types. Transforming a high-level data type into a tensor is called ",(0,o.kt)("inlineCode",{parentName:"p"},"pack")," and transforming a tensor into a high-level data type is called ",(0,o.kt)("inlineCode",{parentName:"p"},"unpack"),"."),(0,o.kt)("p",null,"Each model will have a ",(0,o.kt)("inlineCode",{parentName:"p"},"pack")," and an ",(0,o.kt)("inlineCode",{parentName:"p"},"unpack"),". Both are specified in the PyTorch Live Spec (or Live Spec for short). The Live Spec has to be bundled with the model ",(0,o.kt)("inlineCode",{parentName:"p"},"ptl")," file as ",(0,o.kt)("inlineCode",{parentName:"p"},"extra_files"),"."),(0,o.kt)("p",null,"This section will guide you step-by-step for how to bundle the Live Spec with ",(0,o.kt)("inlineCode",{parentName:"p"},"pack")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"unpack")," for an image classification model, more specifically the MobileNet V3 (small) model."),(0,o.kt)("p",null,"We can do this bundling step from anywhere in our filesystem that has access to ",(0,o.kt)("inlineCode",{parentName:"p"},"python"),", but we'll do it in ",(0,o.kt)("inlineCode",{parentName:"p"},"<PYTORCH_LIVE_PROJECT>/models")," so the bundled model is in place and ready to go when we're done."),(0,o.kt)("h2",{id:"create-live-spec"},"Create Live Spec"),(0,o.kt)("p",null,"Create a ",(0,o.kt)("inlineCode",{parentName:"p"},"live.spec.json")," file and insert the following definition."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json",metastring:"title=live.spec.json",title:"live.spec.json"},'{\n  "pack": {\n    "type": "tensor_from_image",\n    "image": "image",\n    "transforms": [\n      {\n        "type": "image_to_image",\n        "name": "center_crop"\n      },\n      {\n        "type": "image_to_image",\n        "name": "scale",\n        "width": 224,\n        "height": 224\n      },\n      {\n        "type": "image_to_tensor",\n        "name": "rgb_norm",\n        "mean": [0.485, 0.456, 0.406],\n        "std": [0.229, 0.224, 0.225]\n      }\n    ]\n  },\n  "unpack": {\n    "type": "argmax",\n    "dtype": "float",\n    "key": "maxIdx",\n    "valueKey": "confidence"\n  }\n}\n')),(0,o.kt)("h2",{id:"bundle-live-spec-with-model"},"Bundle Live Spec with Model"),(0,o.kt)("p",null,"Next is to download and bundle the Live Spec with the MobileNet V3 model using a Python script."),(0,o.kt)("h3",{id:"set-up-python-virtual-environment"},"Set up Python virtual environment"),(0,o.kt)("p",null,"It is recommended to run the Pyhton script in a virtual environment. Python offers a command to create a virtual environment with the following command."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"python3 -m venv venv\nsource venv/bin/activate\n")),(0,o.kt)("h3",{id:"install-torch-and-torchvision-dependencies"},"Install ",(0,o.kt)("inlineCode",{parentName:"h3"},"torch")," and ",(0,o.kt)("inlineCode",{parentName:"h3"},"torchvision")," dependencies."),(0,o.kt)("p",null,"The Python script requires ",(0,o.kt)("inlineCode",{parentName:"p"},"torch")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"torchvision"),". Use the Python package manager (",(0,o.kt)("inlineCode",{parentName:"p"},"pip"),") to install both dependencies."),(0,o.kt)(i.Z,{defaultValue:"venv",values:[{label:"Virtual Environment",value:"venv"},{label:"No Virtual Environment",value:"no-venv"}],mdxType:"Tabs"},(0,o.kt)(l.Z,{value:"venv",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"pip install torch torchvision\n"))),(0,o.kt)(l.Z,{value:"no-venv",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"pip3 install torch torchvision\n")))),(0,o.kt)("p",null,"The following script will download the MobileNet V3 model from the PyTorch Hub, optimize it for mobile use, and bundle the Live Spec as extra file with the ",(0,o.kt)("inlineCode",{parentName:"p"},"ptl")," file."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-py",metastring:"title=make_model.py",title:"make_model.py"},'from pathlib import Path\n\nimport torch\nimport torchvision\nfrom torch.utils.mobile_optimizer import optimize_for_mobile\n\nmodel = torchvision.models.mobilenet_v3_small(pretrained=True)\nmodel.eval()\n\nscripted_model = torch.jit.script(model)\noptimized_model = optimize_for_mobile(scripted_model)\nspec = Path("live.spec.json").read_text()\nextra_files = {}\nextra_files["model/live.spec.json"] = spec\noptimized_model._save_for_lite_interpreter("mobilenet_v3_small.ptl", _extra_files=extra_files)\n\nprint("model successfully exported")\n')),(0,o.kt)("p",null,"Create the ",(0,o.kt)("inlineCode",{parentName:"p"},"make_model.py")," file, add the Python script above, and then run Python script to create ",(0,o.kt)("inlineCode",{parentName:"p"},"mobilenet_v3_small.ptl"),"."),(0,o.kt)(i.Z,{defaultValue:"venv",values:[{label:"Virtual Environment",value:"venv"},{label:"No Virtual Environment",value:"no-venv"}],mdxType:"Tabs"},(0,o.kt)(l.Z,{value:"venv",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"python make_model.py\n"))),(0,o.kt)(l.Z,{value:"no-venv",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"python3 make_model.py\n")))),(0,o.kt)("p",null,"If you haven't run the commands in the ",(0,o.kt)("inlineCode",{parentName:"p"},"<PYTORCH_LIVE_PROJECT>/models")," directory, copy the ",(0,o.kt)("inlineCode",{parentName:"p"},"mobilenet_v3_small.ptl")," file to the ",(0,o.kt)("inlineCode",{parentName:"p"},"<PYTORCH_LIVE_PROJECT>/models")," directory."),(0,o.kt)("h2",{id:"give-us-feedback"},"Give us feedback"),(0,o.kt)(s.Z,{docTitle:"Prepare Custom Model",mdxType:"SurveyLinkButton"})))}v.isMDXComponent=!0},6010:function(e,t,n){"use strict";function r(e){var t,n,a="";if("string"==typeof e||"number"==typeof e)a+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=r(e[t]))&&(a&&(a+=" "),a+=n);else for(t in e)e[t]&&(a&&(a+=" "),a+=t);return a}function a(){for(var e,t,n=0,a="";n<arguments.length;)(e=arguments[n++])&&(t=r(e))&&(a&&(a+=" "),a+=t);return a}n.d(t,{Z:function(){return a}})}}]);