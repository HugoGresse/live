(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[777],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return d},kt:function(){return m}});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),p=c(n),m=i,h=p["".concat(s,".").concat(m)]||p[m]||u[m]||o;return n?a.createElement(h,r(r({ref:t},d),{},{components:n})):a.createElement(h,r({ref:t},d))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,r=new Array(o);r[0]=p;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,r[1]=l;for(var c=2;c<o;c++)r[c]=n[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},8215:function(e,t,n){"use strict";var a=n(7294);t.Z=function(e){var t=e.children,n=e.hidden,i=e.className;return a.createElement("div",{role:"tabpanel",hidden:n,className:i},t)}},1395:function(e,t,n){"use strict";n.d(t,{Z:function(){return d}});var a=n(7294),i=n(944),o=n(6010),r="tabItem_1uMI",l="tabItemActive_2DSg";var s=37,c=39;var d=function(e){var t=e.lazy,n=e.block,d=e.defaultValue,u=e.values,p=e.groupId,m=e.className,h=(0,i.Z)(),f=h.tabGroupChoices,g=h.setTabGroupChoices,k=(0,a.useState)(d),v=k[0],w=k[1],y=a.Children.toArray(e.children),N=[];if(null!=p){var b=f[p];null!=b&&b!==v&&u.some((function(e){return e.value===b}))&&w(b)}var C=function(e){var t=e.currentTarget,n=N.indexOf(t),a=u[n].value;w(a),null!=p&&(g(p,a),setTimeout((function(){var e,n,a,i,o,r,s,c;(e=t.getBoundingClientRect(),n=e.top,a=e.left,i=e.bottom,o=e.right,r=window,s=r.innerHeight,c=r.innerWidth,n>=0&&o<=c&&i<=s&&a>=0)||(t.scrollIntoView({block:"center",behavior:"smooth"}),t.classList.add(l),setTimeout((function(){return t.classList.remove(l)}),2e3))}),150))},x=function(e){var t,n;switch(e.keyCode){case c:var a=N.indexOf(e.target)+1;n=N[a]||N[0];break;case s:var i=N.indexOf(e.target)-1;n=N[i]||N[N.length-1]}null==(t=n)||t.focus()};return a.createElement("div",{className:"tabs-container"},a.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":n},m)},u.map((function(e){var t=e.value,n=e.label;return a.createElement("li",{role:"tab",tabIndex:v===t?0:-1,"aria-selected":v===t,className:(0,o.Z)("tabs__item",r,{"tabs__item--active":v===t}),key:t,ref:function(e){return N.push(e)},onKeyDown:x,onFocus:C,onClick:C},n)}))),t?(0,a.cloneElement)(y.filter((function(e){return e.props.value===v}))[0],{className:"margin-vert--md"}):a.createElement("div",{className:"margin-vert--md"},y.map((function(e,t){return(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==v})}))))}},9443:function(e,t,n){"use strict";var a=(0,n(7294).createContext)(void 0);t.Z=a},944:function(e,t,n){"use strict";var a=n(7294),i=n(9443);t.Z=function(){var e=(0,a.useContext)(i.Z);if(null==e)throw new Error("`useUserPreferencesContext` is used outside of `Layout` Component.");return e}},896:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return c},metadata:function(){return d},toc:function(){return u},default:function(){return m}});var a=n(2122),i=n(9756),o=(n(7294),n(3905)),r=n(1395),l=n(8215),s=["components"],c={id:"mnist-digit-classification",sidebar_position:7},d={unversionedId:"tutorials/mnist-digit-classification",id:"tutorials/mnist-digit-classification",isDocsHomePage:!1,title:"MNIST Digit Classification",description:"In this tutorial we will use a model trained on the MNIST dataset of handwritten digits to predict the number that the user draws.",source:"@site/docs/tutorials/mnist-digit-classification.mdx",sourceDirName:"tutorials",slug:"/tutorials/mnist-digit-classification",permalink:"/docs/tutorials/mnist-digit-classification",editUrl:"https://github.com/pytorch/live/edit/main/website/docs/tutorials/mnist-digit-classification.mdx",version:"current",sidebarPosition:7,frontMatter:{id:"mnist-digit-classification",sidebar_position:7},sidebar:"docs",previous:{title:"Question Answering",permalink:"/docs/tutorials/question-answering"},next:{title:"Prepare Custom Model",permalink:"/docs/tutorials/prepare-custom-model"}},u=[{value:"In this tutorial we will use a model trained on the MNIST dataset of handwritten digits to predict the number that the user draws.",id:"in-this-tutorial-we-will-use-a-model-trained-on-the-mnist-dataset-of-handwritten-digits-to-predict-the-number-that-the-user-draws",children:[]},{value:"Create a new React Native project",id:"create-a-new-react-native-project",children:[]},{value:"Adding Basic UI",id:"adding-basic-ui",children:[{value:"The PyTorch Live Canvas Component",id:"the-pytorch-live-canvas-component",children:[]},{value:"The <code>onLayout</code> Prop",id:"the-onlayout-prop",children:[]},{value:"Results placeholders",id:"results-placeholders",children:[]}]},{value:"Filling the Canvas",id:"filling-the-canvas",children:[]},{value:"Drawing with Touch Input",id:"drawing-with-touch-input",children:[]},{value:"Avoiding Excessive Re-rendering",id:"avoiding-excessive-re-rendering",children:[{value:"Running the Model",id:"running-the-model",children:[]}]},{value:"Creating an Image from our Canvas",id:"creating-an-image-from-our-canvas",children:[]},{value:"Running the Model &amp; Displaying Results",id:"running-the-model--displaying-results",children:[]}],p={toc:u};function m(e){var t=e.components,c=(0,i.Z)(e,s);return(0,o.kt)("wrapper",(0,a.Z)({},p,c,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("div",{className:"tutorial-page"},(0,o.kt)("h3",{id:"in-this-tutorial-we-will-use-a-model-trained-on-the-mnist-dataset-of-handwritten-digits-to-predict-the-number-that-the-user-draws"},"In this tutorial we will use a model trained on the MNIST dataset of handwritten digits to predict the number that the user draws."),(0,o.kt)("p",null,"There are several pieces to this tutorial, so please follow each step carefully. If you get lost, completed examples of each step can be found ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/pytorch/live/tree/main/examples/mnist-digit-classification/"},"here"),"."),(0,o.kt)("p",null,"If you haven't installed the PyTorch Live CLI yet, please ",(0,o.kt)("a",{parentName:"p",href:"get-started"},"follow this tutorial")," to get started."),(0,o.kt)("h2",{id:"create-a-new-react-native-project"},"Create a new React Native project"),(0,o.kt)("p",null,"We will start by creating a new React Native project with the PyTorch Live (PTL) template using the CLI. Run the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli init MNISTClassifier\n")),(0,o.kt)("p",null,"Once that is done, let's go into a our newly created project and run it!"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"cd MNISTClassifier\n")),(0,o.kt)(r.Z,{defaultValue:"android",values:[{label:"Android",value:"android"},{label:"iOS (Simulator)",value:"ios"}],mdxType:"Tabs"},(0,o.kt)(l.Z,{value:"android",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-android\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(8422).Z,title:"Screenshot of app after fresh init with CLI"}))),(0,o.kt)(l.Z,{value:"ios",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-ios\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(3559).Z,title:"Screenshot of app after fresh init with CLI"})))),(0,o.kt)("h2",{id:"adding-basic-ui"},"Adding Basic UI"),(0,o.kt)("p",null,"The aim of this tutorial is to help you become more familiar with PTL core components, so we will not spend time on how to style UI, but rather provide the layout and styles from the start."),(0,o.kt)("p",null,"Go ahead and start by copying the following code into the file ",(0,o.kt)("inlineCode",{parentName:"p"},"src/demos/MyDemos.tsx"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},"import React, {useState} from 'react';\nimport {StyleSheet, Text, View} from 'react-native';\nimport {Canvas, CanvasRenderingContext2D} from 'react-native-pytorch-core';\nimport {useSafeAreaInsets} from 'react-native-safe-area-context';\n\nexport default function MNISTDemo() {\n  // Get safe area insets to account for notches, etc.\n  const insets = useSafeAreaInsets();\n  const [canvasSize, setCanvasSize] = useState<number>(0);\n  // `ctx` is drawing context to draw shapes\n  const [ctx, setCtx] = useState<CanvasRenderingContext2D>();\n\n  return (\n    <View\n      style={styles.container}\n      onLayout={event => {\n        const {layout} = event.nativeEvent;\n        setCanvasSize(Math.min(layout?.width || 0, layout?.height || 0));\n      }}>\n      <View style={[styles.instruction, {marginTop: insets.top}]}>\n        <Text style={styles.label}>Write a number</Text>\n        <Text style={styles.label}>Let's test the MNIST model</Text>\n      </View>\n      <Canvas\n        style={{\n          height: canvasSize,\n          width: canvasSize,\n        }}\n        onContext2D={setCtx}\n      />\n      <View style={[styles.resultView]} pointerEvents=\"none\">\n        <Text style={[styles.label, styles.secondary]}>\n          Highest confidence will go here\n        </Text>\n        <Text style={[styles.label, styles.secondary]}>\n          Second highest will go here\n        </Text>\n      </View>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    height: '100%',\n    width: '100%',\n    backgroundColor: '#180b3b',\n    justifyContent: 'center',\n    alignItems: 'center',\n  },\n  resultView: {\n    position: 'absolute',\n    bottom: 0,\n    alignSelf: 'flex-start',\n    flexDirection: 'column',\n    padding: 15,\n  },\n  instruction: {\n    position: 'absolute',\n    top: 0,\n    alignSelf: 'flex-start',\n    flexDirection: 'column',\n    padding: 15,\n  },\n  label: {\n    fontSize: 16,\n    color: '#ffffff',\n  },\n  secondary: {\n    color: '#ffffff99',\n  },\n});\n")),(0,o.kt)("p",null,"Now you should see UI that looks exactly like the screenshot below."),(0,o.kt)(r.Z,{defaultValue:"android",values:[{label:"Android",value:"android"},{label:"iOS (Simulator)",value:"ios"}],mdxType:"Tabs"},(0,o.kt)(l.Z,{value:"android",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-android\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(4905).Z,title:"Screenshot of UI created with initial code"}))),(0,o.kt)(l.Z,{value:"ios",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-ios\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(5606).Z,title:"Screenshot of UI created with initial code"})))),(0,o.kt)("p",null,"Before we add more code, let's take a second to discuss some of what the above code does."),(0,o.kt)("h3",{id:"the-pytorch-live-canvas-component"},"The PyTorch Live Canvas Component"),(0,o.kt)("p",null,"We'll be using the PTL canvas in this tutorial to let the user draw numbers that we will try to classify."),(0,o.kt)("p",null,"Just like the name suggests, a canvas is a surface that we can programatically draw on."),(0,o.kt)("p",null,"In order to draw things on a canvas, we use what is called the canvas context, the ",(0,o.kt)("inlineCode",{parentName:"p"},"ctx")," state variable in this case."),(0,o.kt)("p",null,"Note that we haven't used the context to draw anything yet, so our canvas is essentially invisible."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx"},".\n.\n.\nexport default function MNISTDemo() {\n.\n.\n.\n  const [ctx, setCtx] = useState<CanvasRenderingContext2D>();\n.\n.\n.\n      <Canvas\n        style={{\n          height: canvasSize,\n          width: canvasSize,\n        }}\n        onContext2D={setCtx}\n      />\n.\n.\n.\n")),(0,o.kt)("h3",{id:"the-onlayout-prop"},"The ",(0,o.kt)("inlineCode",{parentName:"h3"},"onLayout")," Prop"),(0,o.kt)("p",null,"In our code, we use the ",(0,o.kt)("inlineCode",{parentName:"p"},"onLayout")," prop on the container view to get the dimensions of the screen space we are working with."),(0,o.kt)("p",null,"Once we have the dimensions of the screen, we find which is smaller between the screen width and height and then we use that to size our canvas."),(0,o.kt)("p",null,"This makes sure that our canvas is square and fits within the bounds of our screen in both portrait and landscape."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx"},".\n.\n.\nexport default function MNISTDemo() {\n  // Get safe area insets to account for notches, etc.\n  const insets = useSafeAreaInsets();\n  const [canvasSize, setCanvasSize] = useState<number>(0);\n.\n.\n.\n  return (\n    <View\n      style={styles.container}\n      onLayout={event => {\n        const {layout} = event.nativeEvent;\n        setCanvasSize(Math.min(layout?.width || 0, layout?.height || 0));\n      }}>\n.\n.\n.\n")),(0,o.kt)("h3",{id:"results-placeholders"},"Results placeholders"),(0,o.kt)("p",null,"Note that for now we just have placeholder text where we will put our model results. Later on, after we run the model, we will update the text there to display the results."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx"},'.\n.\n.\n  <View style={[styles.resultView]} pointerEvents="none">\n    <Text style={[styles.label, styles.secondary]}>\n      Highest confidence will go here\n    </Text>\n    <Text style={[styles.label, styles.secondary]}>\n      Second highest will go here\n    </Text>\n  </View>\n.\n.\n.\n')),(0,o.kt)("h2",{id:"filling-the-canvas"},"Filling the Canvas"),(0,o.kt)("p",null,"Like we mentioned in the previous section, our canvas is currently completely blank."),(0,o.kt)("p",null,"Let's change that and make a clear surface for users to draw on."),(0,o.kt)("p",null,"Here's a short summary of the changes we're introducing:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Import ",(0,o.kt)("inlineCode",{parentName:"p"},"useCallback")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"useEffect")," from React")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Define a color for our canvas background (",(0,o.kt)("inlineCode",{parentName:"p"},"COLOR_CANVAS_BACKGROUND"),"). We'll use a lighter purple color to distinguish from the rest of the screen.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a ",(0,o.kt)("inlineCode",{parentName:"p"},"draw")," function that will fill in our background. We create it with ",(0,o.kt)("inlineCode",{parentName:"p"},"useCallback")," to make it so the function updates everytime the context or size of the canvas change."),(0,o.kt)("p",{parentName:"li"},"a. Check to make sure context is not null so we have something to draw with"),(0,o.kt)("p",{parentName:"li"},"b. Set the context's fill style to our canvas background purple (essentially choosing which marker to work with)"),(0,o.kt)("p",{parentName:"li"},"c. Fill in a rectangle that starts at the origin coordinate (0,0) on our canvas (the top left corner) and ends in the bottom right corner of our canvas so it covers the whole thing"),(0,o.kt)("p",{parentName:"li"},"d. Call the ",(0,o.kt)("inlineCode",{parentName:"p"},"invalidate")," function on our canvas context to let the screen know that we've draw new things for it to show.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Trigger the ",(0,o.kt)("inlineCode",{parentName:"p"},"draw")," anytime it changes with the ",(0,o.kt)("inlineCode",{parentName:"p"},"useEffect")," block. Remember that ",(0,o.kt)("inlineCode",{parentName:"p"},"draw")," changes everytime the canvas context or size change, so essentially this ",(0,o.kt)("inlineCode",{parentName:"p"},"useEffect")," runs every time the canvas changes."))),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"useCallback")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"useEffect")," that we imported as well as the ",(0,o.kt)("inlineCode",{parentName:"p"},"useState")," function we already had imported are examples of ",(0,o.kt)("strong",{parentName:"p"},"React Hooks"),". Hooks allow React function components, like our ",(0,o.kt)("inlineCode",{parentName:"p"},"MNISTDemo")," function component, to remember things."),(0,o.kt)("p",{parentName:"div"},"You'll notice at the end of ",(0,o.kt)("inlineCode",{parentName:"p"},"useCallback")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"useEffect")," we have a list ",(0,o.kt)("inlineCode",{parentName:"p"},"[]"),'. This list is the list of "dependencies" for that hook. This just means that the hook will hold onto the value we give it until one of the "dependencies" changes, in which case it will update the value it remembers.'),(0,o.kt)("p",{parentName:"div"},"For more information on React Hooks, head over to the ",(0,o.kt)("a",{parentName:"p",href:"https://reactjs.org/docs/hooks-intro.html"},"React docs")," where you can read or watch explanations."))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},"import React, {useCallback, useEffect, useState} from 'react';\nimport {StyleSheet, Text, View} from 'react-native';\nimport {Canvas, CanvasRenderingContext2D} from 'react-native-pytorch-core';\nimport {useSafeAreaInsets} from 'react-native-safe-area-context';\n\nconst COLOR_CANVAS_BACKGROUND = '#4F25C6';\n\nexport default function MNISTDemo() {\n  // Get safe area insets to account for notches, etc.\n  const insets = useSafeAreaInsets();\n  const [canvasSize, setCanvasSize] = useState<number>(0);\n  // `ctx` is drawing context to draw shapes\n  const [ctx, setCtx] = useState<CanvasRenderingContext2D>();\n\n  const draw = useCallback(() => {\n    if (ctx != null) {\n      // fill background by drawing a rect\n      ctx.fillStyle = COLOR_CANVAS_BACKGROUND;\n      ctx.fillRect(0, 0, canvasSize, canvasSize);\n\n      ctx.invalidate();\n    }\n  }, [ctx, canvasSize]);\n\n  useEffect(() => {\n    draw();\n  }, [draw]);\n\n  return (\n    <View\n      style={styles.container}\n      onLayout={event => {\n        const {layout} = event.nativeEvent;\n        setCanvasSize(Math.min(layout?.width || 0, layout?.height || 0));\n      }}>\n      <View style={[styles.instruction, {marginTop: insets.top}]}>\n        <Text style={styles.label}>Write a number</Text>\n        <Text style={styles.label}>Let's test the MNIST model</Text>\n      </View>\n      <Canvas\n        style={{\n          height: canvasSize,\n          width: canvasSize,\n        }}\n        onContext2D={setCtx}\n      />\n      <View style={[styles.resultView]} pointerEvents=\"none\">\n        <Text style={[styles.label, styles.secondary]}>\n          Highest confidence will go here\n        </Text>\n        <Text style={[styles.label, styles.secondary]}>\n          Second highest will go here\n        </Text>\n      </View>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    height: '100%',\n    width: '100%',\n    backgroundColor: '#180b3b',\n    justifyContent: 'center',\n    alignItems: 'center',\n  },\n  resultView: {\n    position: 'absolute',\n    bottom: 0,\n    alignSelf: 'flex-start',\n    flexDirection: 'column',\n    padding: 15,\n  },\n  instruction: {\n    position: 'absolute',\n    top: 0,\n    alignSelf: 'flex-start',\n    flexDirection: 'column',\n    padding: 15,\n  },\n  label: {\n    fontSize: 16,\n    color: '#ffffff',\n  },\n  secondary: {\n    color: '#ffffff99',\n  },\n});\n")),(0,o.kt)("p",null,"Once you run your app, the My Demos screen should now look like this."),(0,o.kt)(r.Z,{defaultValue:"android",values:[{label:"Android",value:"android"},{label:"iOS (Simulator)",value:"ios"}],mdxType:"Tabs"},(0,o.kt)(l.Z,{value:"android",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-android\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(791).Z,title:"Screenshot of app after painting canvas light purple"}))),(0,o.kt)(l.Z,{value:"ios",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-ios\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(8925).Z,title:"Screenshot of app after painting canvas light purple"})))),(0,o.kt)("p",null,"I know that was a lot of new stuff to simply paint our canvas light purple, but it provides us with a good foundation for when we draw more on our canvas."),(0,o.kt)("h2",{id:"drawing-with-touch-input"},"Drawing with Touch Input"),(0,o.kt)("p",null,"Now that we have a clear area for the user to draw on, let's make it so they can draw!"),(0,o.kt)("p",null,"Let's go over what we changed to make drawing possible:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Import ",(0,o.kt)("inlineCode",{parentName:"p"},"useRef")," from React.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Define a color for the trail of the users touch (",(0,o.kt)("inlineCode",{parentName:"p"},"COLOR_TRAIL_STROKE"),"). We'll use white to make it stand out.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Define a ",(0,o.kt)("inlineCode",{parentName:"p"},"TrailPoint")," type to keep our data safe, error free, and easy to use")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a ref to a list of ",(0,o.kt)("inlineCode",{parentName:"p"},"TrailPoints")," called ",(0,o.kt)("inlineCode",{parentName:"p"},"trailRef")," and set it to an empty list.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Keep track of if the user has finished drawing with the ",(0,o.kt)("inlineCode",{parentName:"p"},"drawingDone")," state variable and initialize it to ",(0,o.kt)("inlineCode",{parentName:"p"},"false"),".")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Add support for drawing the trail to our draw function:"),(0,o.kt)("p",{parentName:"li"},"a. Create a variable called ",(0,o.kt)("inlineCode",{parentName:"p"},"trail")," and set it to the current value of our ",(0,o.kt)("inlineCode",{parentName:"p"},"trailRef"),". This is purely so we don't have to write ",(0,o.kt)("inlineCode",{parentName:"p"},"trailRef.current")," everytime we need the trail.\nb. Check to make sure the trail isn't null\nc. Draw our background to cover anything previously drawing\nd. Check to make sure our trail has at least 1 point\ne. Set the context's ",(0,o.kt)("inlineCode",{parentName:"p"},"strokeColor")," - you can think of it as picking the marker color we'll draw lines with\nf. Set the context's line drawing style parameters (",(0,o.kt)("inlineCode",{parentName:"p"},"lineWidth"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"lineJoin"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"lineCap"),", and ",(0,o.kt)("inlineCode",{parentName:"p"},"miterLimit"),")\ng. Tell the context to start a line at the first point in the trail\nh. Loop through points of the trail to add them to the line we are drawing\ni. Tell the context via the ",(0,o.kt)("inlineCode",{parentName:"p"},"stroke")," method to actually draw the line that we constructed\ng. Use the ",(0,o.kt)("inlineCode",{parentName:"p"},"invalidate")," method to tell the screen we have updates ready to draw")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create functions for handling when a user touches the canvas (",(0,o.kt)("inlineCode",{parentName:"p"},"handleStart"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"handleTouch"),", and ",(0,o.kt)("inlineCode",{parentName:"p"},"handleEnd"),")")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"handleStart")," is called when the user first touches the canvas. It is a simple function that does the following:"),(0,o.kt)("p",{parentName:"li"},"a. Set the ",(0,o.kt)("inlineCode",{parentName:"p"},"drawingDone")," variable to ",(0,o.kt)("inlineCode",{parentName:"p"},"false"),"\nb. Reset the trailRef to an ",(0,o.kt)("inlineCode",{parentName:"p"},"emptyList"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"handleMove")," function is called each time the device detects that the touch has changed positions since the starting touch."),(0,o.kt)("p",{parentName:"li"},"a. Get the coordinates of the new touch location and store them in the ",(0,o.kt)("inlineCode",{parentName:"p"},"position")," variable\nb. If there are already points in the ",(0,o.kt)("inlineCode",{parentName:"p"},"trail"),", only add the new position if it's 5 pixels away from the last position (avoids keeping unnecesarry points that slow down the app)\nc. If there are no points in the ",(0,o.kt)("inlineCode",{parentName:"p"},"trail"),", add the new position.\nd. Trigger the ",(0,o.kt)("inlineCode",{parentName:"p"},"draw")," function to display the newly updated ",(0,o.kt)("inlineCode",{parentName:"p"},"trail"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"handleEnd")," function is called when the user's touch is no longer detected on the screen."),(0,o.kt)("p",{parentName:"li"},"a. Simply set the ",(0,o.kt)("inlineCode",{parentName:"p"},"drawingDone")," state variable to ",(0,o.kt)("inlineCode",{parentName:"p"},"true"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Set the ",(0,o.kt)("inlineCode",{parentName:"p"},"onTouchStart"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"onTouchMove"),", and ",(0,o.kt)("inlineCode",{parentName:"p"},"onTouchEnd")," props on our ",(0,o.kt)("inlineCode",{parentName:"p"},"<Canvas />")," component to ",(0,o.kt)("inlineCode",{parentName:"p"},"handleStart"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"handleMove"),", and ",(0,o.kt)("inlineCode",{parentName:"p"},"handleEnd")," respectively."))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},"import React, {useCallback, useEffect, useState, useRef} from 'react';\nimport {StyleSheet, Text, View} from 'react-native';\nimport {Canvas, CanvasRenderingContext2D} from 'react-native-pytorch-core';\nimport {useSafeAreaInsets} from 'react-native-safe-area-context';\n\nconst COLOR_CANVAS_BACKGROUND = '#4F25C6';\nconst COLOR_TRAIL_STROKE = '#FFFFFF';\n\ntype TrailPoint = {\n  x: number;\n  y: number;\n};\n\nexport default function MNISTDemo() {\n  // Get safe area insets to account for notches, etc.\n  const insets = useSafeAreaInsets();\n  const [canvasSize, setCanvasSize] = useState<number>(0);\n\n  // `ctx` is drawing context to draw shapes\n  const [ctx, setCtx] = useState<CanvasRenderingContext2D>();\n\n  const trailRef = useRef<TrailPoint[]>([]);\n  const [drawingDone, setDrawingDone] = useState(false);\n\n  const draw = useCallback(() => {\n    if (ctx != null) {\n      const trail = trailRef.current;\n      if (trail != null) {\n        // fill background by drawing a rect\n        ctx.fillStyle = COLOR_CANVAS_BACKGROUND;\n        ctx.fillRect(0, 0, canvasSize, canvasSize);\n\n        // Draw the trail\n\n        if (trail.length > 0) {\n          ctx.strokeStyle = COLOR_TRAIL_STROKE;\n          ctx.lineWidth = 25;\n          ctx.lineJoin = 'round';\n          ctx.lineCap = 'round';\n          ctx.miterLimit = 1;\n          ctx.beginPath();\n          ctx.moveTo(trail[0].x, trail[0].y);\n          for (let i = 1; i < trail.length; i++) {\n            ctx.lineTo(trail[i].x, trail[i].y);\n          }\n          ctx.stroke();\n        }\n\n        ctx.invalidate();\n      }\n    }\n  }, [ctx, canvasSize, trailRef]);\n\n  // handlers for touch events\n  const handleMove = useCallback(\n    async event => {\n      const position: TrailPoint = {\n        x: event.nativeEvent.locationX,\n        y: event.nativeEvent.locationY,\n      };\n      const trail = trailRef.current;\n      if (trail.length > 0) {\n        const lastPosition = trail[trail.length - 1];\n        const dx = position.x - lastPosition.x;\n        const dy = position.y - lastPosition.y;\n        // add a point to trail if distance from last point > 5\n        if (dx * dx + dy * dy > 25) {\n          trail.push(position);\n        }\n      } else {\n        trail.push(position);\n      }\n      draw();\n    },\n    [trailRef, draw],\n  );\n\n  const handleStart = useCallback(() => {\n    setDrawingDone(false);\n    trailRef.current = [];\n  }, [trailRef, setDrawingDone]);\n\n  const handleEnd = useCallback(() => {\n    setDrawingDone(true);\n  }, [setDrawingDone]);\n\n  useEffect(() => {\n    draw();\n  }, [draw]); // update only when layout or context changes\n\n  return (\n    <View\n      style={styles.container}\n      onLayout={event => {\n        const {layout} = event.nativeEvent;\n        setCanvasSize(Math.min(layout?.width || 0, layout?.height || 0));\n      }}>\n      <View style={[styles.instruction, {marginTop: insets.top}]}>\n        <Text style={styles.label}>Write a number</Text>\n        <Text style={styles.label}>\n          Let's see if the AI model will get it right\n        </Text>\n      </View>\n      <Canvas\n        style={{\n          height: canvasSize,\n          width: canvasSize,\n        }}\n        onContext2D={setCtx}\n        onTouchMove={handleMove}\n        onTouchStart={handleStart}\n        onTouchEnd={handleEnd}\n      />\n      {drawingDone && (\n        <View style={[styles.resultView]} pointerEvents=\"none\">\n          <Text style={[styles.label, styles.secondary]}>\n            Highest confidence will go here\n          </Text>\n          <Text style={[styles.label, styles.secondary]}>\n            Second highest will go here\n          </Text>\n        </View>\n      )}\n    </View>\n  );\n}\n.\n.\n.\n")),(0,o.kt)("p",null,"Run this code and we should now be able to do some drawing like you can see in the video below."),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(7047).Z,title:"Screen recording of drawing on canvas with laggy screen"})),(0,o.kt)("p",null,"As you will notice, the drawing seems to glitch out at times, especially as the trail gets longer and longer. Let's fix that next."),(0,o.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("h4",{parentName:"div",id:"react-refs"},"React Refs"),(0,o.kt)("p",{parentName:"div"},"Refs in React are a variable like state, but they don't cause the component to re-render when they are changed."),(0,o.kt)("p",{parentName:"div"},"You can get or set the value of a ref via the ",(0,o.kt)("inlineCode",{parentName:"p"},".current")," property."),(0,o.kt)("p",{parentName:"div"},"In our code, we access the trail with ",(0,o.kt)("inlineCode",{parentName:"p"},"trailRef.current"),". We set the trail in our ",(0,o.kt)("inlineCode",{parentName:"p"},"handleStart")," function to an empty list with ",(0,o.kt)("inlineCode",{parentName:"p"},"trailRef.current = []"),"."))),(0,o.kt)("h2",{id:"avoiding-excessive-re-rendering"},"Avoiding Excessive Re-rendering"),(0,o.kt)("p",null,"The glitchiness we see in our code as it stands is because we are asking the screen to refresh before it is ready."),(0,o.kt)("p",null,"Mobile screens typically refresh 60 times per second (though some new phones refresh twice as often). When we display things with React, it takes care of matching our devices refresh pace."),(0,o.kt)("p",null,"While we are using React to render our ",(0,o.kt)("inlineCode",{parentName:"p"},"<Canvas />"),", what we draw on our canvas we handle ourselves. Lucky for us, there is a simple way to make sure we don't render too often."),(0,o.kt)("p",null,"To address this, we will make a few updates to our code, mainly in the ",(0,o.kt)("inlineCode",{parentName:"p"},"draw")," function:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a ref called ",(0,o.kt)("inlineCode",{parentName:"p"},"animationHandleRef")," that can be a ",(0,o.kt)("inlineCode",{parentName:"p"},"number")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"null")," and set it to ",(0,o.kt)("inlineCode",{parentName:"p"},"null"),". We will use this ref to check if rendering is currently in process or not.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Use the ",(0,o.kt)("inlineCode",{parentName:"p"},"animationHandleRef")," in the ",(0,o.kt)("inlineCode",{parentName:"p"},"draw")," function to control how often we rerender:"),(0,o.kt)("p",{parentName:"li"},"a. Start the function by checking if the ",(0,o.kt)("inlineCode",{parentName:"p"},"animationHandleRef")," is set to a non-null value. If it is, we want to end early, because we know the device is already working on rendering.\nb. Wrap our code that does drawing in an inline function that we pass to ",(0,o.kt)("inlineCode",{parentName:"p"},"requestAnimationFrame")," and set the ",(0,o.kt)("inlineCode",{parentName:"p"},"animationHandleRef"),"'s value to what it returns. (Read more about this function in the note following the code)\nc. After telling our canvas we are ready for a rerender with ",(0,o.kt)("inlineCode",{parentName:"p"},"ctx.invalidate()"),", clear the ",(0,o.kt)("inlineCode",{parentName:"p"},"animationHandleRef")," by setting it's value to null.\nd. Add ",(0,o.kt)("inlineCode",{parentName:"p"},"animationHandleRef")," to the ",(0,o.kt)("inlineCode",{parentName:"p"},"draw")," function's callback dependencies list."))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},".\n.\n.\nexport default function MNISTDemo() {\n  // Get safe area insets to account for notches, etc.\n  const insets = useSafeAreaInsets();\n  const [canvasSize, setCanvasSize] = useState<number>(0);\n\n  // `ctx` is drawing context to draw shapes\n  const [ctx, setCtx] = useState<CanvasRenderingContext2D>();\n\n  const trailRef = useRef<TrailPoint[]>([]);\n  const [drawingDone, setDrawingDone] = useState(false);\n  const animationHandleRef = useRef<number | null>(null);\n\n  const draw = useCallback(() => {\n    if (animationHandleRef.current != null) return;\n    if (ctx != null) {\n      animationHandleRef.current = requestAnimationFrame(() => {\n        const trail = trailRef.current;\n        if (trail != null) {\n          // fill background by drawing a rect\n          ctx.fillStyle = COLOR_CANVAS_BACKGROUND;\n          ctx.fillRect(0, 0, canvasSize, canvasSize);\n\n          // Draw the trail\n          ctx.strokeStyle = COLOR_TRAIL_STROKE;\n          ctx.lineWidth = 25;\n          ctx.lineJoin = 'round';\n          ctx.lineCap = 'round';\n          ctx.miterLimit = 1;\n\n          if (trail.length > 0) {\n            ctx.beginPath();\n            ctx.moveTo(trail[0].x, trail[0].y);\n            for (let i = 1; i < trail.length; i++) {\n              ctx.lineTo(trail[i].x, trail[i].y);\n            }\n          }\n          ctx.stroke();\n          // Need to include this at the end, for now.\n          ctx.invalidate();\n          animationHandleRef.current = null;\n        }\n      });\n    }\n  }, [animationHandleRef, ctx, canvasSize, trailRef]);\n.\n.\n.\n")),(0,o.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("h4",{parentName:"div",id:"what-does-requestanimationframe-do"},"What does ",(0,o.kt)("inlineCode",{parentName:"h4"},"requestAnimationFrame")," do?"),(0,o.kt)("p",{parentName:"div"},(0,o.kt)("inlineCode",{parentName:"p"},"requestAnimationFrame")," is a utility function that helps us run code when the screen is ready for the next rerender."),(0,o.kt)("p",{parentName:"div"},"Input: a callback function as a parameter and then runs that function when the screen next refreshes."),(0,o.kt)("p",{parentName:"div"},"Output: a number that functions as an ID for the callback. You can use that number to cancel the callback if you later decide you don't want to run the code. (We don't need that feature for this)"))),(0,o.kt)("p",null,"Once you have those changes in your code, go ahead and refresh the app and see how much smoother drawing is."),(0,o.kt)(r.Z,{defaultValue:"android",values:[{label:"Android",value:"android"},{label:"iOS (Simulator)",value:"ios"}],mdxType:"Tabs"},(0,o.kt)(l.Z,{value:"android",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-android\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(8418).Z,title:"Screen recording of drawing on canvas with smooth animation"}))),(0,o.kt)(l.Z,{value:"ios",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-ios\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(1386).Z,title:"Screen recording of drawing on canvas with smooth animation"})))),(0,o.kt)("p",null,"With silky smooth drawing in place, we are now ready to start working with our the MNIST model."),(0,o.kt)("h3",{id:"running-the-model"},"Running the Model"),(0,o.kt)("p",null,"We'll start by creating a React hook that provides a function for running inference on an input image. We'll follow React hooks naming conventions and call ours ",(0,o.kt)("inlineCode",{parentName:"p"},"useMNISTModel"),"."),(0,o.kt)("p",null,"Let's summarize the changes we're making:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Import ",(0,o.kt)("inlineCode",{parentName:"li"},"Image")," and ",(0,o.kt)("inlineCode",{parentName:"li"},"MobileModel")," from ",(0,o.kt)("inlineCode",{parentName:"li"},"react-native-pytorch-core")),(0,o.kt)("li",{parentName:"ol"},"Load the model file with the ",(0,o.kt)("inlineCode",{parentName:"li"},"require")," function and call it ",(0,o.kt)("inlineCode",{parentName:"li"},"mnistModel")),(0,o.kt)("li",{parentName:"ol"},"Create a type called ",(0,o.kt)("inlineCode",{parentName:"li"},"MNISTResult")," with the following properties:\na. ",(0,o.kt)("inlineCode",{parentName:"li"},"num")," -  a digit from 0 to 9\nb. ",(0,o.kt)("inlineCode",{parentName:"li"},"score")," - the confidence the model has in the input image being the given ",(0,o.kt)("inlineCode",{parentName:"li"},"num")),(0,o.kt)("li",{parentName:"ol"},"Define a function called ",(0,o.kt)("inlineCode",{parentName:"li"},"useMNISTModel")," that does the following\na. Creates a React callback async function called ",(0,o.kt)("inlineCode",{parentName:"li"},"processImage")," that takes in ",(0,o.kt)("inlineCode",{parentName:"li"},"Image")," as a parameter and does the following\ni. Uses the ",(0,o.kt)("inlineCode",{parentName:"li"},"MobileModel")," api to execute the ",(0,o.kt)("inlineCode",{parentName:"li"},"mnistModel")," we loaded with a set of parameters that tell the model how much of the image to use and what the foreground and background colors are.\nii. Transform the raw scores into ",(0,o.kt)("inlineCode",{parentName:"li"},"MNISTResult")," objects\niii. Sort the results by ",(0,o.kt)("inlineCode",{parentName:"li"},"score"),"\niv. return the sorted results\nb. Returns an object containing the ",(0,o.kt)("inlineCode",{parentName:"li"},"processImage")," function we just created")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},"import React, {useCallback, useEffect, useState, useRef} from 'react';\nimport {StyleSheet, Text, View} from 'react-native';\nimport {\n  Canvas,\n  CanvasRenderingContext2D,\n  Image,\n  MobileModel,\n} from 'react-native-pytorch-core';\nimport {useSafeAreaInsets} from 'react-native-safe-area-context';\n\nconst COLOR_CANVAS_BACKGROUND = '#4F25C6';\nconst COLOR_TRAIL_STROKE = '#FFFFFF';\n\ntype TrailPoint = {\n  x: number;\n  y: number;\n};\n\n// This is the custom model you have trained. See the tutorial for more on preparing a PyTorch model for mobile.\nconst mnistModel = require('../../models/mnist.ptl');\n\ntype MNISTResult = {\n  num: number;\n  score: number;\n};\n\n/**\n * The React hook provides MNIST model inference on an input image.\n */\nfunction useMNISTModel() {\n  const processImage = useCallback(async (image: Image) => {\n    // Runs model inference on input image\n    const {\n      result: {scores},\n    } = await MobileModel.execute<{scores: number[]}>(mnistModel, {\n      image,\n      crop_width: 1,\n      crop_height: 1,\n      scale_width: 28,\n      scale_height: 28,\n      colorBackground: COLOR_CANVAS_BACKGROUND,\n      colorForeground: COLOR_TRAIL_STROKE,\n    });\n\n    // Get the score of each number (index), and sort the array by the most likely first.\n    const sortedScore: MNISTResult[] = scores\n      .map((score, index) => ({score: score, num: index}))\n      .sort((a, b) => b.score - a.score);\n    return sortedScore;\n  }, []);\n\n  return {\n    processImage,\n  };\n}\n\nexport default function MNISTDemo() {\n.\n.\n.\n")),(0,o.kt)("p",null,"An even shorter summary: it takes in an ",(0,o.kt)("inlineCode",{parentName:"p"},"Image")," and gives back a list of sorted results."),(0,o.kt)("p",null,"But, we don't have ",(0,o.kt)("inlineCode",{parentName:"p"},"Image"),"s. We just have a trail on a canvas."),(0,o.kt)("p",null,"In the next section, we'll learn how to create an ",(0,o.kt)("inlineCode",{parentName:"p"},"Image")," from the contents of our canvas that we can pass to the model."),(0,o.kt)("h2",{id:"creating-an-image-from-our-canvas"},"Creating an Image from our Canvas"),(0,o.kt)("p",null,"We are going to create another hook called ",(0,o.kt)("inlineCode",{parentName:"p"},"useMNISTCanvasInference")," that uses the hook we just created (",(0,o.kt)("inlineCode",{parentName:"p"},"useMNISTModel"),")."),(0,o.kt)("p",null,"This hook will take in the ",(0,o.kt)("inlineCode",{parentName:"p"},"canvasSize")," and give us back two things:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"result")," - a state variable that holds the sorted list of ",(0,o.kt)("inlineCode",{parentName:"li"},"MNISTResult"),"s from the model"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"classify")," - a function that takes in the ",(0,o.kt)("inlineCode",{parentName:"li"},"canvas")," context, extracts an image from it, processes the image, and then updates the ",(0,o.kt)("inlineCode",{parentName:"li"},"result")," state variable")),(0,o.kt)("p",null,"In our ",(0,o.kt)("inlineCode",{parentName:"p"},"classify")," callback, we use some of the PTL core components, including the newly imported ",(0,o.kt)("inlineCode",{parentName:"p"},"ImageUtil")," object."),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"ImageUtil")," object allows us to take the ",(0,o.kt)("inlineCode",{parentName:"p"},"imageData")," we pull from the canvas and turn it into an ",(0,o.kt)("inlineCode",{parentName:"p"},"Image")," that can be used by our model."),(0,o.kt)("p",null,"You'll also see that we call the ",(0,o.kt)("inlineCode",{parentName:"p"},"release")," function on both our ",(0,o.kt)("inlineCode",{parentName:"p"},"imageData")," and our ",(0,o.kt)("inlineCode",{parentName:"p"},"image")," variables as soon as we are done using them. This is a vital step to make sure we don't run out of memory on images we no longer need."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},"import React, {useCallback, useEffect, useState, useRef} from 'react';\nimport {StyleSheet, Text, View} from 'react-native';\nimport {\n  Canvas,\n  CanvasRenderingContext2D,\n  Image,\n  ImageUtil,\n  MobileModel,\n} from 'react-native-pytorch-core';\nimport {useSafeAreaInsets} from 'react-native-safe-area-context';\n.\n.\n.\n\n/**\n * The React hook provides MNIST inference using the image data extracted from\n * a canvas.\n *\n * @param canvasSize The size of the square canvas\n */\nfunction useMNISTCanvasInference(canvasSize: number) {\n  const [result, setResult] = useState<MNISTResult[]>();\n  const {processImage} = useMNISTModel();\n  const classify = useCallback(\n    async (ctx: CanvasRenderingContext2D) => {\n      // Return immediately if canvas is size 0\n      if (canvasSize === 0) {\n        return null;\n      }\n\n      // Get image data center crop\n      const imageData = await ctx.getImageData(0, 0, canvasSize, canvasSize);\n\n      // Convert image data to image.\n      const image: Image = await ImageUtil.fromImageData(imageData);\n\n      // Release image data to free memory\n      imageData.release();\n\n      // Run MNIST inference on the image\n      const result = await processImage(image);\n\n      // Release image to free memory\n      image.release();\n\n      // Set result state to force re-render of component that uses this hook\n      setResult(result);\n    },\n    [canvasSize, processImage, setResult],\n  );\n  return {\n    result,\n    classify,\n  };\n}\n\nexport default function MNISTDemo() {\n.\n.\n.\n")),(0,o.kt)("p",null,"With this second hook, we are ready to run our model with the user created drawings. Let's hook it up in the next section."),(0,o.kt)("h2",{id:"running-the-model--displaying-results"},"Running the Model & Displaying Results"),(0,o.kt)("p",null,"While we add a decent amount of lines in this section, they are all simple changes."),(0,o.kt)("p",null,"Let's cut to the summary:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Create a type called ",(0,o.kt)("inlineCode",{parentName:"li"},"NumberLabelSet")," so we know what kind of data we have access to about a number"),(0,o.kt)("li",{parentName:"ol"},"Create a list of ",(0,o.kt)("inlineCode",{parentName:"li"},"NumberLabelSet")," objects and call it ",(0,o.kt)("inlineCode",{parentName:"li"},"numLabels")),(0,o.kt)("li",{parentName:"ol"},"Get the ",(0,o.kt)("inlineCode",{parentName:"li"},"classify")," method and ",(0,o.kt)("inlineCode",{parentName:"li"},"result")," state variable by calling ",(0,o.kt)("inlineCode",{parentName:"li"},"useMNISTCanvasInference")," from within our demo component."),(0,o.kt)("li",{parentName:"ol"},"Update the ",(0,o.kt)("inlineCode",{parentName:"li"},"handleEnd")," function to check for a canvas context and then trigger the model"),(0,o.kt)("li",{parentName:"ol"},"Add ",(0,o.kt)("inlineCode",{parentName:"li"},"classify")," as a dependency to the ",(0,o.kt)("inlineCode",{parentName:"li"},"handleEnd")," callback function"),(0,o.kt)("li",{parentName:"ol"},"Change the text in the results section to reflect the numbers from the model output")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:'title="MyDemos.tsx"',title:'"MyDemos.tsx"'},".\n.\n.\ntype NumberLabelSet = {\n  english: string;\n  asciiSymbol: string;\n};\n\nconst numLabels: NumberLabelSet[] = [\n  {\n    english: 'zero',\n    asciiSymbol: '\ud83c\udd0c',\n  },\n  {\n    english: 'one',\n    asciiSymbol: '\u278a',\n  },\n  {\n    english: 'two',\n    asciiSymbol: '\u278b',\n  },\n  {\n    english: 'three',\n    asciiSymbol: '\u278c',\n  },\n  {\n    english: 'four',\n    asciiSymbol: '\u278d',\n  },\n  {\n    english: 'five',\n    asciiSymbol: '\u278e',\n  },\n  {\n    english: 'six',\n    asciiSymbol: '\u278f',\n  },\n  {\n    english: 'seven',\n    asciiSymbol: '\u2790',\n  },\n  {\n    english: 'eight',\n    asciiSymbol: '\u2791',\n  },\n  {\n    english: 'nine',\n    asciiSymbol: '\u2792',\n  },\n];\n\nexport default function MNISTDemo() {\n  // Get safe area insets to account for notches, etc.\n  const insets = useSafeAreaInsets();\n  const [canvasSize, setCanvasSize] = useState<number>(0);\n\n  // `ctx` is drawing context to draw shapes\n  const [ctx, setCtx] = useState<CanvasRenderingContext2D>();\n\n  const {classify, result} = useMNISTCanvasInference(canvasSize);\n.\n.\n.\n  const handleEnd = useCallback(() => {\n    setDrawingDone(true);\n    if (ctx != null) classify(ctx);\n  }, [setDrawingDone, classify, ctx]);\n.\n.\n.\n      {drawingDone && (\n        <View style={[styles.resultView]} pointerEvents=\"none\">\n          <Text style={[styles.label, styles.secondary]}>\n            {result &&\n              `${numLabels[result[0].num].asciiSymbol} it looks like ${\n                numLabels[result[0].num].english\n              }`}\n          </Text>\n          <Text style={[styles.label, styles.secondary]}>\n            {result &&\n              `${numLabels[result[1].num].asciiSymbol} or it might be ${\n                numLabels[result[1].num].english\n              }`}\n          </Text>\n        </View>\n      )}\n.\n.\n.\n")),(0,o.kt)("p",null,"When you run the code, you should see it display results properly in the bottom left corner like the screen recording below."),(0,o.kt)(r.Z,{defaultValue:"android",values:[{label:"Android",value:"android"},{label:"iOS (Simulator)",value:"ios"}],mdxType:"Tabs"},(0,o.kt)(l.Z,{value:"android",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-android\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(6853).Z,title:"Screen recording of user drawing numbers and model results displaying correct answers"}))),(0,o.kt)(l.Z,{value:"ios",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"npx torchlive-cli run-ios\n")),(0,o.kt)("p",null,"  ",(0,o.kt)("img",{src:n(2378).Z,title:"Screen recording of user drawing numbers and model results displaying correct answers"})))),(0,o.kt)("p",null,"And with that we have a working MNIST classifier!")))}m.isMDXComponent=!0},6010:function(e,t,n){"use strict";function a(e){var t,n,i="";if("string"==typeof e||"number"==typeof e)i+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=a(e[t]))&&(i&&(i+=" "),i+=n);else for(t in e)e[t]&&(i&&(i+=" "),i+=t);return i}function i(){for(var e,t,n=0,i="";n<arguments.length;)(e=arguments[n++])&&(t=a(e))&&(i&&(i+=" "),i+=t);return i}n.d(t,{Z:function(){return i}})},791:function(e,t,n){"use strict";t.Z=n.p+"assets/images/fill-canvas-bg-28b400d22a34fadf4c4de449ed693fb7.png"},8422:function(e,t,n){"use strict";t.Z=n.p+"assets/images/first-run-25e23131120ec484ac24093ae32f4e52.png"},7047:function(e,t,n){"use strict";t.Z=n.p+"assets/images/initial-laggy-drawing-c6bd0fd480b9447796b75c42e352660a.gif"},4905:function(e,t,n){"use strict";t.Z=n.p+"assets/images/initial-ui-86fbf0aab1a7879ea9860047b6747a68.png"},6853:function(e,t,n){"use strict";t.Z=n.p+"assets/images/model-running-4737b32d9223fa45252bb0bd40c7ec97.gif"},8418:function(e,t,n){"use strict";t.Z=n.p+"assets/images/smooth-drawing-fef31df85942c963d03dbf0e27f36a0b.gif"},8925:function(e,t,n){"use strict";t.Z=n.p+"assets/images/fill-canvas-bg-6de24bad15e27ab95af7eabd056975d8.png"},3559:function(e,t,n){"use strict";t.Z=n.p+"assets/images/first-run-141ff37378121bc763a8a597ec83ab89.png"},5606:function(e,t,n){"use strict";t.Z=n.p+"assets/images/initial-ui-5d1e78d48dc0914bc079c189d763c17c.png"},2378:function(e,t,n){"use strict";t.Z=n.p+"assets/images/model-running-48bbdaacc834c991b4455df205dd2b3b.gif"},1386:function(e,t,n){"use strict";t.Z=n.p+"assets/images/smooth-drawing-040b8d7cc9cbaf2edee98af4e2684d59.gif"}}]);